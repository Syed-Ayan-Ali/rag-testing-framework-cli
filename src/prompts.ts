export const multipleQueryPrompt = `generate a list of 5 queries in json format, in the format: {[q1: "", q2:"", ...]}, using the given content. The queries will be used to fill a column in a database table called "nlp_chunk_description." This column will contain a list of queries that the user may ask for which the content is the answer. Since the content is a chunk, it may be that queries can only be answered by combining different chunks together so even though the query cannot be answered ocompletely by the content, the query should be added to the list. An example fo this would be "What are the basel iii requirements for tier 1 banks in hong kong?". This query cannot be answered using one chunk. It needs to be answered by combining different chunks together. The query should be added to the list of every chunk that is relevant to basel, hong kong, and tier 1 banks and other relevant keywords. At the end, strip only the 5 queries itself, and remove all the text generated by the LLM.`;
export const singleQueryPrompt = `generate a single query in json format, in the format: {[q1: ""}], using the given content. The query will be used to fill a column in a database table called "chunk_description" This column will contain one query that the user may ask for which the content is the answer. Since the content is a chunk, it may be that queries can only be answered by combining different chunks together so even though the query cannot be answered ocompletely by the content, the query should be added to the list. An example fo this would be "What are the basel iii requirements for tier 1 banks in hong kong?". This query cannot be answered using one chunk. It needs to be answered by combining different chunks together. The query should be added to the list of every chunk that is relevant to basel, hong kong, and tier 1 banks and other relevant keywords. At the end, strip only the query itself, and remove all the text generated by the LLM.`;